{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face Recognition Software - LiveFeed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Register A Face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tkinter\n",
    "import tkinter.simpledialog\n",
    "import cv2\n",
    "import PIL.Image, PIL.ImageTk\n",
    "import time\n",
    "\n",
    "\n",
    "class App:\n",
    " def __init__(self, window, window_title, video_source=0):\n",
    "     self.window = window\n",
    "     self.window.title(window_title)\n",
    "     self.video_source = video_source\n",
    "\n",
    "     # open video source (by default this will try to open the computer webcam)\n",
    "     self.vid = MyVideoCapture(self.video_source)\n",
    "\n",
    "     # Create a canvas that can fit the above video source size\n",
    "     self.canvas = tkinter.Canvas(window, width = self.vid.width, height = self.vid.height)\n",
    "     self.canvas.pack()\n",
    "\n",
    "     # Button that lets the user take a snapshot\n",
    "     self.btn_snapshot=tkinter.Button(window, text=\"Register Face\", width=50, command=self.snapshot)\n",
    "     self.btn_snapshot.pack(anchor=tkinter.CENTER, expand=True)\n",
    "\n",
    "     # After it is called once, the update method will be automatically called every delay milliseconds\n",
    "     self.delay = 10\n",
    "     self.update()\n",
    "     self.window.mainloop()\n",
    "\n",
    " def snapshot(self):\n",
    "     face_encodings = {}\n",
    "     ret, frame = self.vid.get_frame()\n",
    "     y2,x2,y1,x1 = fr.face_locations(frame)[0]\n",
    "     cropped = frame[y2-30:y1, x1 : x2]\n",
    "     cropped = cv2.cvtColor(cropped, cv2.COLOR_RGB2BGR)\n",
    "     if ret:\n",
    "         name = tkinter.simpledialog.askstring(\"Face Details\", \"Please Enter the Name\")\n",
    "         cv2.imwrite(f\"Faces/images/{name}\" + \".jpg\", cropped)\n",
    "         \n",
    "         try:\n",
    "            with open('Faces/faces_dataset.dat', 'rb') as f:\n",
    "                face_encodings = pickle.load(f)\n",
    "         except:\n",
    "            pass\n",
    "        \n",
    "         face_encodings[name] = fr.face_encodings(cropped)[0]   \n",
    "         with open('Faces/faces_dataset.dat', 'wb') as f:\n",
    "            pickle.dump(face_encodings, f)\n",
    "    \n",
    " def update(self):\n",
    "     # Get a frame from the video source\n",
    "     ret, frame = self.vid.get_frame()\n",
    "     detect_frame = detect_face(frame)\n",
    "     \n",
    "     if detect_frame is not None:\n",
    "        frame = detect_frame\n",
    "     \n",
    "     if ret:\n",
    "         self.photo = PIL.ImageTk.PhotoImage(image = PIL.Image.fromarray(frame))\n",
    "         self.canvas.create_image(0, 0, image = self.photo, anchor = tkinter.NW)\n",
    "\n",
    "     self.window.after(self.delay, self.update)\n",
    "\n",
    "\n",
    "class MyVideoCapture:\n",
    " def __init__(self, video_source=0):\n",
    "     # Open the video source\n",
    "     self.vid = cv2.VideoCapture(video_source)\n",
    "     if not self.vid.isOpened():\n",
    "         raise ValueError(\"Unable to open video source\", video_source)\n",
    "\n",
    "     # Get video source width and height\n",
    "     self.width = self.vid.get(cv2.CAP_PROP_FRAME_WIDTH)\n",
    "     self.height = self.vid.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
    "\n",
    " def get_frame(self):\n",
    "     if self.vid.isOpened():\n",
    "         ret, frame = self.vid.read()\n",
    "         if ret:\n",
    "             # Return a boolean success flag and the current frame converted to BGR\n",
    "             return (ret, cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "         else:\n",
    "             return (ret, None)\n",
    "     else:\n",
    "         return (ret, None)\n",
    "\n",
    " # Release the video source when the object is destroyed\n",
    " def __del__(self):\n",
    "     if self.vid.isOpened():\n",
    "         self.vid.release()\n",
    "\n",
    "# Create a window and pass it to the Application object\n",
    "App(tkinter.Tk(), \"Tkinter and OpenCV\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recognize_all(img):\n",
    "    cpy = img.copy()\n",
    "    try:\n",
    "        with open('Faces/faces_dataset.dat', 'rb') as f:\n",
    "            face_encodings = pickle.load(f)\n",
    "        face_names = list(face_encodings.keys())\n",
    "        face_encodings = np.array(list(face_encodings.values()))\n",
    "\n",
    "        new_faces_coordinates = fr.face_locations(img)\n",
    "\n",
    "        for i in new_faces_coordinates:\n",
    "            name = 'Unknown'\n",
    "            y2,x2,y1,x1 = i\n",
    "            cropped = img[y2:y1, x1:x2]\n",
    "            unknown_enc = fr.face_encodings(cropped)\n",
    "            matches = fr.compare_faces(face_encodings, unknown_enc)\n",
    "\n",
    "            if True in matches:\n",
    "                match_index = matches.index(True)\n",
    "                name = face_names[match_index]\n",
    "                \n",
    "            cpy = cv2.rectangle(cpy, (x1,y1), (x2, y2), (0,255,255), 1)\n",
    "            cpy = cv2.putText(cpy,name,(x1,y2), cv2.FONT_HERSHEY_SIMPLEX, 1,(255,255,255),2,cv2.LINE_AA)\n",
    "    except:\n",
    "        pass\n",
    "    return cpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(3, 640)\n",
    "cap.set(4, 480)\n",
    "# cap.set(cv2.CAP_PROP_FPS, 30) \n",
    "\n",
    "while True:\n",
    "#     print(cap.get(cv2.CAP_PROP_FPS))\n",
    "    ret,frame = cap.read()\n",
    "    detect_frame = recognize_all(frame)\n",
    "#     recognise_face()\n",
    "    if detect_frame is not None:\n",
    "        cv2.imshow('Face Recognition',detect_frame)\n",
    "    else:\n",
    "        cv2.imshow('Face Recognition', frame)\n",
    "\n",
    "    if cv2.waitKey(1) in (ord('q'),27):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -----------------------------*---------------------------------*-----------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import face_recognition as fr\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from tkinter import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing the Code###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display(img):\n",
    "    fig = plt.figure(figsize = (10,8))\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.imshow(img)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = fr.load_image_file(\"../images/known/himanshu.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_fake = fr.load_image_file(\"../images/car.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_face(img):\n",
    "    cpy = img.copy()\n",
    "    faces_detected = fr.face_locations(img)\n",
    "    print(faces_detected)\n",
    "    for i in range(len(faces_detected)):\n",
    "        y2,x2,y1,x1 = faces_detected[i]\n",
    "        cpy = cv2.rectangle(cpy, (x1,y1), (x2, y2), (0,255,255), 1)\n",
    "    return cpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_landmarks(img):\n",
    "    image = img.copy()\n",
    "    try:\n",
    "        dict_locations = fr.face_landmarks(image)[0]\n",
    "        lst_locations = list(dict_locations.values())\n",
    "        for x in range(len(lst_locations)):\n",
    "            for y in range(1,len(lst_locations[x])):\n",
    "                cv2.line(image, lst_locations[x][y-1], lst_locations[x][y], (255,255,255), 1)\n",
    "        return image\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "while True:\n",
    "    ret,frame = cap.read()\n",
    "    detect_frame = show_landmarks(detect_face(frame))\n",
    "    if detect_frame is not None:\n",
    "        cv2.imshow('Face Recognition',detect_frame)\n",
    "    else:\n",
    "        cv2.imshow('Face Recognition', frame)\n",
    "    if cv2.waitKey(1) in (ord('q'),27):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recognise_face(train, test):\n",
    "    biden_encoding = fr.face_encodings(train)[0]\n",
    "    unknown_encoding = fr.face_encodings(test)[0]\n",
    "    print(biden_encoding)\n",
    "    results = fr.compare_faces([biden_encoding], unknown_encoding)\n",
    "    print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img = img.copy()\n",
    "test_img = fr.load_image_file(\"../images/unknown/test.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "recognise_face(train_img,test_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Face Recognition Image Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import face_recognition as fr\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Faces/faces_dataset.dat', 'rb') as f:\n",
    "    face_encodings = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_names = list(face_encodings.keys())\n",
    "face_encodings = np.array(list(face_encodings.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "unknown_image = fr.load_image_file(\"Faces/images/ratan.jpg\")\n",
    "unknown_encoding = fr.face_encodings(unknown_image)\n",
    "result = fr.compare_faces(face_encodings, unknown_encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('himanshu', False), ('ratan', True)]\n"
     ]
    }
   ],
   "source": [
    "names_with_result = list(zip(face_names, result))\n",
    "print(names_with_result)\n",
    "name = list(filter(lambda x: x[1] == True, names_with_result))[0][0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
